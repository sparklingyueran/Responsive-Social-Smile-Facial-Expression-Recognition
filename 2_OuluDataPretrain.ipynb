{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pretrain on OULU-CASIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "# import dlib\n",
    "import time\n",
    "import sys\n",
    "import torch.utils.data as data\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable  \n",
    "from PIL import Image\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset \n",
    "import numpy as np\n",
    "from torch.utils import data as Data\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from ops.basic_ops import ConsensusModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import  transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfennet import *\n",
    "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis =  visdom.Visdom(env=u'rss',use_incoming_socket=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(data.Dataset):\n",
    "    '''\n",
    "    the format of sampleLib:[tensor,label],[tensor,label],[tensor,label].......\n",
    "    \n",
    "    '''\n",
    "    def __init__(self,sampleLib):\n",
    "        self.sampleLib=sampleLib\n",
    "#         self.transform = transforms.Compose([\n",
    "#                                                transforms.ToTensor()\n",
    "#                                            ])\n",
    "    def __getitem__(self,index):\n",
    "        [sample,label] = self.sampleLib[index]\n",
    "        return sample, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sampleLib)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleLib = torch.load('/.../oulu_group_0.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformed_dataset = Mydataset(sampleLib = torch.load('/.../oulu_trans_video_tensor_list.pkl') )\n",
    "# check loading\n",
    "# 查看数据的导入是否成功\n",
    "assert(transformed_dataset[0][0].shape == torch.Size([7, 3, 224, 224]))\n",
    "assert(transformed_dataset[0][1] == 0)\n",
    "assert(len(transformed_dataset) == 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# split into 10 groups for cross-validation\n",
    "# 分成10个group存起来\n",
    "sampleLib = torch.load('/.../oulu_trans_video_tensor_list.pkl')\n",
    "for i in tqdm(range(10)):\n",
    "    sampleLib_group_i = sampleLib[48*i : 48*(i+1)]\n",
    "    sampleLib_no_i = sampleLib[0:48*i]+ sampleLib[48*(i+1):480]\n",
    "    dataset_group_i = Mydataset(sampleLib_group_i)\n",
    "    dataset_no_i = Mydataset(sampleLib_no_i)\n",
    "    torch.save(dataset_group_i, '/.../oulu_group_{}.pkl'.format(i))\n",
    "    torch.save(dataset_no_i, '/.../oulu_group_no_{}.pkl'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "one_train = torch.load('/.../oulu_group_no_{}.pkl'.format(i))\n",
    "one_test = torch.load('/.../oulu_group_{}.pkl'.format(i))\n",
    "assert(one_train[0][0].shape == torch.Size([7, 3, 224, 224]))\n",
    "assert(one_train[0][1] == 0)\n",
    "assert(len(one_train) == 480-48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)Pretrain on OULU-CASIA 在Oulu数据集上pretrain表情模型TFEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* input_train ='/.../oulu_group_no_{}.pkl'.format(i)\n",
    "* input_test ='/.../oulu_group_{}.pkl'.format(i))\n",
    "\n",
    "* input_all = Mydataset(sampleLib = torch.load('/.../oulu_trans_video_tensor_list.pkl') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every SSTEP epochs\"\"\"\n",
    "    lr = lr * (0.01 ** (epoch // sstep))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def validation(test_loader,net):\n",
    "    pred_list = []\n",
    "    test_y_list = []\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_y_list.append(test_dataset[i][1])\n",
    "    #     test_loader.size\n",
    "    for step, (test_x,test_y) in enumerate(test_loader):\n",
    "#         test_x = test_x.to(DEVICE)\n",
    "        test_x = test_x.cuda()\n",
    "        test_y =test_y.numpy()\n",
    "\n",
    "        test_output = net(test_x)                   \n",
    "        pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\n",
    "\n",
    "        pred_list +=  list(pred_y  )\n",
    "\n",
    "    pred_ay = np.array(pred_list)\n",
    "    test_y_ay = np.array(test_y_list)\n",
    "\n",
    "    accu = float((pred_ay ==test_y_ay).astype(int).sum())/test_y_ay.size\n",
    "    return accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross-validation\n",
    "time_start=time.time()\n",
    "\n",
    "\n",
    "loss_10 = []\n",
    "accu_10 = []\n",
    "net_10 = []\n",
    "group_list = [0,1,2,3,4,5,6,7,8,9]\n",
    "for i in group_list:\n",
    "    BATCH_SIZE =16\n",
    "    print('start loading data')\n",
    "    train_dataset = torch.load('/.../oulu_group_no_{}.pkl'.format(i))\n",
    "    \n",
    "    train_loader = Data.DataLoader(\n",
    "        dataset=train_dataset,      \n",
    "        batch_size=BATCH_SIZE,      \n",
    "        shuffle = False,               \n",
    "    )\n",
    "    test_dataset = torch.load('/.../oulu_group_{}.pkl'.format(i))\n",
    "    test_loader = Data.DataLoader(\n",
    "        dataset=test_dataset,     \n",
    "        batch_size=BATCH_SIZE,     \n",
    "        shuffle = False,               \n",
    "    )\n",
    "    print('finish loading data')\n",
    "    net = TFEN_6()\n",
    "#     net = torch.nn.DataParallel(net.cuda(), device_ids=[3])\n",
    "    net = net.cuda()\n",
    "    \n",
    "    EPOCH = 400\n",
    "    LR = 0.001\n",
    "    MOMENTUM = 0.9\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    sstep = 70\n",
    "\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    loss_his = []\n",
    "    accu_list = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        \n",
    "#         print('====FOLDER:{}====EPOCH:{}/{}===='.format(i,epoch,EPOCH))\n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch, LR)\n",
    "        \n",
    "        for step, (batch_x,batch_y) in enumerate(train_loader):\n",
    "\n",
    "            batch_x = batch_x.cuda()\n",
    "            batch_y = batch_y.cuda()\n",
    "\n",
    "            out = net(batch_x)\n",
    "            loss = loss_func(out,batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_his.append(loss.data.cpu().numpy())\n",
    "                        \n",
    "            if step % 50 == 0:\n",
    "                accuracy = validation(test_loader,net)\n",
    "                accu_list.append(accuracy)\n",
    "                print('Step:{}, Accuracy Rate:{}'.format(step,accuracy))\n",
    "                \n",
    "                \n",
    "                \n",
    "                if accuracy == max(accu_list):\n",
    "                    net_best = net\n",
    "                \n",
    "                \n",
    "                \n",
    "                x= torch.Tensor([len(accu_list)])\n",
    "                y=torch.Tensor([accuracy])\n",
    "                vis.line(X=x, Y=y, \n",
    "                         win='oulu_{}'.format(i), \n",
    "                    opts=dict(\n",
    "#                         legend=['oulu_adjustlr0.01_sstep70_2_{}'.format(i)],\n",
    "                        title='oulu_{}'.format(i),\n",
    "                        width=800,\n",
    "                        height=800,\n",
    "                             ),\n",
    "                         update='append' if len(accu_list)>0 else None)\n",
    "\n",
    "    loss_10.append(loss_his)\n",
    "    accu_10.append(accu_list)\n",
    "    net_10.append(net_best)\n",
    "    \n",
    "\n",
    "\n",
    "time_end=time.time()\n",
    "m, s = divmod(time_end-time_start, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print (\"%02d:%02d:%02d\" % (h, m, s))\n",
    "\n",
    "m, s = divmod(time_end-time_start, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print (\"%02d:%02d:%02d\" % (h, m, s))\n",
    "\n",
    "torch.save(net_10,'torch14_adjustlr0.01_sstep7.pkl')\n",
    "torch.save(accu_10,'torch14_adjustlr0.01_sstep70.pkl')\n",
    "torch.save(loss_10,'torch14_adjustlr0.01_sstep70.pkl')\n",
    "print(time.strftime('torch14_adjustlr0.01_sstep70.pkl ===> %Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}